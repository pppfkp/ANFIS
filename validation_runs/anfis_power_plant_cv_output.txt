Loading dataset from powerPlant.csv...
Training fold 1...
Epoch 1/200, Training Loss: 148975.0537
Epoch 1/200, Training Loss: 148975.0537, Validation Loss: 95443.7031
Epoch 1: EarlyStopping initialized with best_loss=95443.7031
Epoch 2/200, Training Loss: 68803.2330
Epoch 2/200, Training Loss: 68803.2330, Validation Loss: 44615.5625
Epoch 2: Validation loss improved to 44615.5625
Epoch 3/200, Training Loss: 33078.9561
Epoch 3/200, Training Loss: 33078.9561, Validation Loss: 35775.7578
Epoch 3: Validation loss improved to 35775.7578
Epoch 4/200, Training Loss: 22641.8393
Epoch 4/200, Training Loss: 22641.8393, Validation Loss: 22293.8613
Epoch 4: Validation loss improved to 22293.8613
Epoch 5/200, Training Loss: 19440.5645
Epoch 5/200, Training Loss: 19440.5645, Validation Loss: 16160.5547
Epoch 5: Validation loss improved to 16160.5547
Epoch 6/200, Training Loss: 14169.4808
Epoch 6/200, Training Loss: 14169.4808, Validation Loss: 12877.0508
Epoch 6: Validation loss improved to 12877.0508
Epoch 7/200, Training Loss: 11558.6745
Epoch 7/200, Training Loss: 11558.6745, Validation Loss: 10778.2471
Epoch 7: Validation loss improved to 10778.2471
Epoch 8/200, Training Loss: 9466.4923
Epoch 8/200, Training Loss: 9466.4923, Validation Loss: 9346.3008
Epoch 8: Validation loss improved to 9346.3008
Epoch 9/200, Training Loss: 7908.8795
Epoch 9/200, Training Loss: 7908.8795, Validation Loss: 7436.0068
Epoch 9: Validation loss improved to 7436.0068
Epoch 10/200, Training Loss: 5997.3110
Epoch 10/200, Training Loss: 5997.3110, Validation Loss: 5388.4160
Epoch 10: Validation loss improved to 5388.4160
Epoch 11/200, Training Loss: 6112.9766
Epoch 11/200, Training Loss: 6112.9766, Validation Loss: 4831.2622
Epoch 11: Validation loss improved to 4831.2622
Epoch 12/200, Training Loss: 3579.8082
Epoch 12/200, Training Loss: 3579.8082, Validation Loss: 2993.6494
Epoch 12: Validation loss improved to 2993.6494
Epoch 13/200, Training Loss: 2398.4479
Epoch 13/200, Training Loss: 2398.4479, Validation Loss: 1959.4871
Epoch 13: Validation loss improved to 1959.4871
Epoch 14/200, Training Loss: 1458.4535
Epoch 14/200, Training Loss: 1458.4535, Validation Loss: 1084.5262
Epoch 14: Validation loss improved to 1084.5262
Epoch 15/200, Training Loss: 595.0568
Epoch 15/200, Training Loss: 595.0568, Validation Loss: 129.0618
Epoch 15: Validation loss improved to 129.0618
Epoch 16/200, Training Loss: 54.5681
Epoch 16/200, Training Loss: 54.5681, Validation Loss: 60.0726
Epoch 16: Validation loss improved to 60.0726
Epoch 17/200, Training Loss: 43.7878
Epoch 17/200, Training Loss: 43.7878, Validation Loss: 54.2315
Epoch 17: Validation loss improved to 54.2315
Epoch 18/200, Training Loss: 27.7764
Epoch 18/200, Training Loss: 27.7764, Validation Loss: 19.7981
Epoch 18: Validation loss improved to 19.7981
Epoch 19/200, Training Loss: 21.1679
Epoch 19/200, Training Loss: 21.1679, Validation Loss: 19.7387
Epoch 19: Validation loss improved to 19.7387
Epoch 20/200, Training Loss: 21.2429
Epoch 20/200, Training Loss: 21.2429, Validation Loss: 19.6619
Epoch 20: Validation loss improved to 19.6619
Epoch 21/200, Training Loss: 21.2084
Epoch 21/200, Training Loss: 21.2084, Validation Loss: 19.6889
Epoch 21: No improvement. EarlyStopping counter: 1/5
Epoch 22/200, Training Loss: 21.3066
Epoch 22/200, Training Loss: 21.3066, Validation Loss: 19.8140
Epoch 22: No improvement. EarlyStopping counter: 2/5
Epoch 23/200, Training Loss: 21.3037
Epoch 23/200, Training Loss: 21.3037, Validation Loss: 20.1393
Epoch 23: No improvement. EarlyStopping counter: 3/5
Epoch 24/200, Training Loss: 21.3246
Epoch 24/200, Training Loss: 21.3246, Validation Loss: 19.8948
Epoch 24: No improvement. EarlyStopping counter: 4/5
Epoch 25/200, Training Loss: 21.2857
Epoch 25/200, Training Loss: 21.2857, Validation Loss: 19.7473
Epoch 25: No improvement. EarlyStopping counter: 5/5
Early stopping triggered at epoch 25
Fold 1 completed.
Training fold 2...
Epoch 1/200, Training Loss: 137122.9838
Epoch 1/200, Training Loss: 137122.9838, Validation Loss: 87087.4141
Epoch 1: EarlyStopping initialized with best_loss=87087.4141
Epoch 2/200, Training Loss: 55337.5966
Epoch 2/200, Training Loss: 55337.5966, Validation Loss: 38502.8125
Epoch 2: Validation loss improved to 38502.8125
Epoch 3/200, Training Loss: 32583.5994
Epoch 3/200, Training Loss: 32583.5994, Validation Loss: 28886.5977
Epoch 3: Validation loss improved to 28886.5977
Epoch 4/200, Training Loss: 25028.2913
Epoch 4/200, Training Loss: 25028.2913, Validation Loss: 21731.9961
Epoch 4: Validation loss improved to 21731.9961
Epoch 5/200, Training Loss: 20979.6079
Epoch 5/200, Training Loss: 20979.6079, Validation Loss: 17209.1621
Epoch 5: Validation loss improved to 17209.1621
Epoch 6/200, Training Loss: 16437.3134
Epoch 6/200, Training Loss: 16437.3134, Validation Loss: 14403.8770
Epoch 6: Validation loss improved to 14403.8770
Epoch 7/200, Training Loss: 13053.7249
Epoch 7/200, Training Loss: 13053.7249, Validation Loss: 12920.1426
Epoch 7: Validation loss improved to 12920.1426
Epoch 8/200, Training Loss: 10200.4449
Epoch 8/200, Training Loss: 10200.4449, Validation Loss: 7953.2847
Epoch 8: Validation loss improved to 7953.2847
Epoch 9/200, Training Loss: 7447.9009
Epoch 9/200, Training Loss: 7447.9009, Validation Loss: 6061.6997
Epoch 9: Validation loss improved to 6061.6997
Epoch 10/200, Training Loss: 5658.3781
Epoch 10/200, Training Loss: 5658.3781, Validation Loss: 4549.6792
Epoch 10: Validation loss improved to 4549.6792
Epoch 11/200, Training Loss: 3696.6746
Epoch 11/200, Training Loss: 3696.6746, Validation Loss: 3142.4893
Epoch 11: Validation loss improved to 3142.4893
Epoch 12/200, Training Loss: 2383.9408
Epoch 12/200, Training Loss: 2383.9408, Validation Loss: 1725.3696
Epoch 12: Validation loss improved to 1725.3696
Epoch 13/200, Training Loss: 1445.5734
Epoch 13/200, Training Loss: 1445.5734, Validation Loss: 1065.1501
Epoch 13: Validation loss improved to 1065.1501
Epoch 14/200, Training Loss: 793.1213
Epoch 14/200, Training Loss: 793.1213, Validation Loss: 504.8124
Epoch 14: Validation loss improved to 504.8124
Epoch 15/200, Training Loss: 359.9124
Epoch 15/200, Training Loss: 359.9124, Validation Loss: 202.2542
Epoch 15: Validation loss improved to 202.2542
Epoch 16/200, Training Loss: 154.7480
Epoch 16/200, Training Loss: 154.7480, Validation Loss: 89.8926
Epoch 16: Validation loss improved to 89.8926
Epoch 17/200, Training Loss: 53.4923
Epoch 17/200, Training Loss: 53.4923, Validation Loss: 32.2107
Epoch 17: Validation loss improved to 32.2107
Epoch 18/200, Training Loss: 25.6103
Epoch 18/200, Training Loss: 25.6103, Validation Loss: 22.0890
Epoch 18: Validation loss improved to 22.0890
Epoch 19/200, Training Loss: 21.2801
Epoch 19/200, Training Loss: 21.2801, Validation Loss: 21.2363
Epoch 19: Validation loss improved to 21.2363
Epoch 20/200, Training Loss: 20.8449
Epoch 20/200, Training Loss: 20.8449, Validation Loss: 21.2624
Epoch 20: No improvement. EarlyStopping counter: 1/5
Epoch 21/200, Training Loss: 20.8580
Epoch 21/200, Training Loss: 20.8580, Validation Loss: 21.3775
Epoch 21: No improvement. EarlyStopping counter: 2/5
Epoch 22/200, Training Loss: 20.8806
Epoch 22/200, Training Loss: 20.8806, Validation Loss: 21.1427
Epoch 22: Validation loss improved to 21.1427
Epoch 23/200, Training Loss: 20.8519
Epoch 23/200, Training Loss: 20.8519, Validation Loss: 21.2393
Epoch 23: No improvement. EarlyStopping counter: 1/5
Epoch 24/200, Training Loss: 20.8750
Epoch 24/200, Training Loss: 20.8750, Validation Loss: 21.3287
Epoch 24: No improvement. EarlyStopping counter: 2/5
Epoch 25/200, Training Loss: 20.9784
Epoch 25/200, Training Loss: 20.9784, Validation Loss: 21.5191
Epoch 25: No improvement. EarlyStopping counter: 3/5
Epoch 26/200, Training Loss: 20.9693
Epoch 26/200, Training Loss: 20.9693, Validation Loss: 21.0774
Epoch 26: Validation loss improved to 21.0774
Epoch 27/200, Training Loss: 20.9488
Epoch 27/200, Training Loss: 20.9488, Validation Loss: 21.3932
Epoch 27: No improvement. EarlyStopping counter: 1/5
Epoch 28/200, Training Loss: 21.0166
Epoch 28/200, Training Loss: 21.0166, Validation Loss: 21.2522
Epoch 28: No improvement. EarlyStopping counter: 2/5
Epoch 29/200, Training Loss: 21.0248
Epoch 29/200, Training Loss: 21.0248, Validation Loss: 21.4702
Epoch 29: No improvement. EarlyStopping counter: 3/5
Epoch 30/200, Training Loss: 21.0451
Epoch 30/200, Training Loss: 21.0451, Validation Loss: 21.1742
Epoch 30: No improvement. EarlyStopping counter: 4/5
Epoch 31/200, Training Loss: 20.9856
Epoch 31/200, Training Loss: 20.9856, Validation Loss: 21.2917
Epoch 31: No improvement. EarlyStopping counter: 5/5
Early stopping triggered at epoch 31
Fold 2 completed.
Training fold 3...
Epoch 1/200, Training Loss: 144546.8914
Epoch 1/200, Training Loss: 144546.8914, Validation Loss: 88843.9922
Epoch 1: EarlyStopping initialized with best_loss=88843.9922
Epoch 2/200, Training Loss: 61632.8479
Epoch 2/200, Training Loss: 61632.8479, Validation Loss: 41520.4180
Epoch 2: Validation loss improved to 41520.4180
Epoch 3/200, Training Loss: 31112.1586
Epoch 3/200, Training Loss: 31112.1586, Validation Loss: 26382.3945
Epoch 3: Validation loss improved to 26382.3945
Epoch 4/200, Training Loss: 19825.8428
Epoch 4/200, Training Loss: 19825.8428, Validation Loss: 17028.4980
Epoch 4: Validation loss improved to 17028.4980
Epoch 5/200, Training Loss: 14966.6946
Epoch 5/200, Training Loss: 14966.6946, Validation Loss: 12710.6152
Epoch 5: Validation loss improved to 12710.6152
Epoch 6/200, Training Loss: 12141.7497
Epoch 6/200, Training Loss: 12141.7497, Validation Loss: 10624.6104
Epoch 6: Validation loss improved to 10624.6104
Epoch 7/200, Training Loss: 10388.1384
Epoch 7/200, Training Loss: 10388.1384, Validation Loss: 10185.7578
Epoch 7: Validation loss improved to 10185.7578
Epoch 8/200, Training Loss: 8540.3537
Epoch 8/200, Training Loss: 8540.3537, Validation Loss: 7711.9185
Epoch 8: Validation loss improved to 7711.9185
Epoch 9/200, Training Loss: 7659.7873
Epoch 9/200, Training Loss: 7659.7873, Validation Loss: 6868.3296
Epoch 9: Validation loss improved to 6868.3296
Epoch 10/200, Training Loss: 7086.3717
Epoch 10/200, Training Loss: 7086.3717, Validation Loss: 5810.5205
Epoch 10: Validation loss improved to 5810.5205
Epoch 11/200, Training Loss: 5673.8363
Epoch 11/200, Training Loss: 5673.8363, Validation Loss: 5073.7578
Epoch 11: Validation loss improved to 5073.7578
Epoch 12/200, Training Loss: 4871.7782
Epoch 12/200, Training Loss: 4871.7782, Validation Loss: 4421.0098
Epoch 12: Validation loss improved to 4421.0098
Epoch 13/200, Training Loss: 4021.1465
Epoch 13/200, Training Loss: 4021.1465, Validation Loss: 3741.0249
Epoch 13: Validation loss improved to 3741.0249
Epoch 14/200, Training Loss: 3289.4781
Epoch 14/200, Training Loss: 3289.4781, Validation Loss: 3018.9302
Epoch 14: Validation loss improved to 3018.9302
Epoch 15/200, Training Loss: 2443.6738
Epoch 15/200, Training Loss: 2443.6738, Validation Loss: 2168.3721
Epoch 15: Validation loss improved to 2168.3721
Epoch 16/200, Training Loss: 1893.9700
Epoch 16/200, Training Loss: 1893.9700, Validation Loss: 1700.1324
Epoch 16: Validation loss improved to 1700.1324
Epoch 17/200, Training Loss: 1444.2592
Epoch 17/200, Training Loss: 1444.2592, Validation Loss: 1235.7067
Epoch 17: Validation loss improved to 1235.7067
Epoch 18/200, Training Loss: 979.4125
Epoch 18/200, Training Loss: 979.4125, Validation Loss: 893.0792
Epoch 18: Validation loss improved to 893.0792
Epoch 19/200, Training Loss: 722.4376
Epoch 19/200, Training Loss: 722.4376, Validation Loss: 603.7746
Epoch 19: Validation loss improved to 603.7746
Epoch 20/200, Training Loss: 401.2247
Epoch 20/200, Training Loss: 401.2247, Validation Loss: 132.0276
Epoch 20: Validation loss improved to 132.0276
Epoch 21/200, Training Loss: 31.3119
Epoch 21/200, Training Loss: 31.3119, Validation Loss: 22.9555
Epoch 21: Validation loss improved to 22.9555
Epoch 22/200, Training Loss: 20.4820
Epoch 22/200, Training Loss: 20.4820, Validation Loss: 22.9616
Epoch 22: No improvement. EarlyStopping counter: 1/5
Epoch 23/200, Training Loss: 32.5513
Epoch 23/200, Training Loss: 32.5513, Validation Loss: 22.9175
Epoch 23: Validation loss improved to 22.9175
Epoch 24/200, Training Loss: 20.4842
Epoch 24/200, Training Loss: 20.4842, Validation Loss: 22.7891
Epoch 24: Validation loss improved to 22.7891
Epoch 25/200, Training Loss: 20.4602
Epoch 25/200, Training Loss: 20.4602, Validation Loss: 22.6657
Epoch 25: Validation loss improved to 22.6657
Epoch 26/200, Training Loss: 20.5181
Epoch 26/200, Training Loss: 20.5181, Validation Loss: 22.7122
Epoch 26: No improvement. EarlyStopping counter: 1/5
Epoch 27/200, Training Loss: 20.5599
Epoch 27/200, Training Loss: 20.5599, Validation Loss: 22.8580
Epoch 27: No improvement. EarlyStopping counter: 2/5
Epoch 28/200, Training Loss: 20.5310
Epoch 28/200, Training Loss: 20.5310, Validation Loss: 23.0027
Epoch 28: No improvement. EarlyStopping counter: 3/5
Epoch 29/200, Training Loss: 20.5394
Epoch 29/200, Training Loss: 20.5394, Validation Loss: 22.9790
Epoch 29: No improvement. EarlyStopping counter: 4/5
Epoch 30/200, Training Loss: 20.5769
Epoch 30/200, Training Loss: 20.5769, Validation Loss: 22.9241
Epoch 30: No improvement. EarlyStopping counter: 5/5
Early stopping triggered at epoch 30
Fold 3 completed.
Training fold 4...
Epoch 1/200, Training Loss: 143582.3084
Epoch 1/200, Training Loss: 143582.3084, Validation Loss: 95596.1797
Epoch 1: EarlyStopping initialized with best_loss=95596.1797
Epoch 2/200, Training Loss: 67965.6921
Epoch 2/200, Training Loss: 67965.6921, Validation Loss: 49672.1250
Epoch 2: Validation loss improved to 49672.1250
Epoch 3/200, Training Loss: 35760.1564
Epoch 3/200, Training Loss: 35760.1564, Validation Loss: 26356.2441
Epoch 3: Validation loss improved to 26356.2441
Epoch 4/200, Training Loss: 22127.4867
Epoch 4/200, Training Loss: 22127.4867, Validation Loss: 17012.8262
Epoch 4: Validation loss improved to 17012.8262
Epoch 5/200, Training Loss: 15729.3070
Epoch 5/200, Training Loss: 15729.3070, Validation Loss: 13106.2734
Epoch 5: Validation loss improved to 13106.2734
Epoch 6/200, Training Loss: 11488.7666
Epoch 6/200, Training Loss: 11488.7666, Validation Loss: 10238.3027
Epoch 6: Validation loss improved to 10238.3027
Epoch 7/200, Training Loss: 10618.1215
Epoch 7/200, Training Loss: 10618.1215, Validation Loss: 9449.3438
Epoch 7: Validation loss improved to 9449.3438
Epoch 8/200, Training Loss: 8858.0249
Epoch 8/200, Training Loss: 8858.0249, Validation Loss: 8675.1475
Epoch 8: Validation loss improved to 8675.1475
Epoch 9/200, Training Loss: 7810.8905
Epoch 9/200, Training Loss: 7810.8905, Validation Loss: 7532.1870
Epoch 9: Validation loss improved to 7532.1870
Epoch 10/200, Training Loss: 6985.4600
Epoch 10/200, Training Loss: 6985.4600, Validation Loss: 6510.9790
Epoch 10: Validation loss improved to 6510.9790
Epoch 11/200, Training Loss: 6047.8231
Epoch 11/200, Training Loss: 6047.8231, Validation Loss: 5505.1357
Epoch 11: Validation loss improved to 5505.1357
Epoch 12/200, Training Loss: 4911.2248
Epoch 12/200, Training Loss: 4911.2248, Validation Loss: 4448.6611
Epoch 12: Validation loss improved to 4448.6611
Epoch 13/200, Training Loss: 3891.7992
Epoch 13/200, Training Loss: 3891.7992, Validation Loss: 3825.3816
Epoch 13: Validation loss improved to 3825.3816
Epoch 14/200, Training Loss: 3132.1828
Epoch 14/200, Training Loss: 3132.1828, Validation Loss: 2525.1025
Epoch 14: Validation loss improved to 2525.1025
Epoch 15/200, Training Loss: 2145.4210
Epoch 15/200, Training Loss: 2145.4210, Validation Loss: 1785.8086
Epoch 15: Validation loss improved to 1785.8086
Epoch 16/200, Training Loss: 1426.2499
Epoch 16/200, Training Loss: 1426.2499, Validation Loss: 1218.4198
Epoch 16: Validation loss improved to 1218.4198
Epoch 17/200, Training Loss: 884.7748
Epoch 17/200, Training Loss: 884.7748, Validation Loss: 209.4106
Epoch 17: Validation loss improved to 209.4106
Epoch 18/200, Training Loss: 42.5767
Epoch 18/200, Training Loss: 42.5767, Validation Loss: 21.3171
Epoch 18: Validation loss improved to 21.3171
Epoch 19/200, Training Loss: 21.7170
Epoch 19/200, Training Loss: 21.7170, Validation Loss: 20.0038
Epoch 19: Validation loss improved to 20.0038
Epoch 20/200, Training Loss: 21.1538
Epoch 20/200, Training Loss: 21.1538, Validation Loss: 19.7777
Epoch 20: Validation loss improved to 19.7777
Epoch 21/200, Training Loss: 21.2149
Epoch 21/200, Training Loss: 21.2149, Validation Loss: 19.6222
Epoch 21: Validation loss improved to 19.6222
Epoch 22/200, Training Loss: 21.2505
Epoch 22/200, Training Loss: 21.2505, Validation Loss: 19.7500
Epoch 22: No improvement. EarlyStopping counter: 1/5
Epoch 23/200, Training Loss: 21.2197
Epoch 23/200, Training Loss: 21.2197, Validation Loss: 19.9359
Epoch 23: No improvement. EarlyStopping counter: 2/5
Epoch 24/200, Training Loss: 21.2967
Epoch 24/200, Training Loss: 21.2967, Validation Loss: 19.7844
Epoch 24: No improvement. EarlyStopping counter: 3/5
Epoch 25/200, Training Loss: 21.2126
Epoch 25/200, Training Loss: 21.2126, Validation Loss: 20.3770
Epoch 25: No improvement. EarlyStopping counter: 4/5
Epoch 26/200, Training Loss: 21.3575
Epoch 26/200, Training Loss: 21.3575, Validation Loss: 20.1301
Epoch 26: No improvement. EarlyStopping counter: 5/5
Early stopping triggered at epoch 26
Fold 4 completed.
Training fold 5...
Epoch 1/200, Training Loss: 143994.9547
Epoch 1/200, Training Loss: 143994.9547, Validation Loss: 89454.3125
Epoch 1: EarlyStopping initialized with best_loss=89454.3125
Epoch 2/200, Training Loss: 62879.5186
Epoch 2/200, Training Loss: 62879.5186, Validation Loss: 45448.9531
Epoch 2: Validation loss improved to 45448.9531
Epoch 3/200, Training Loss: 31365.4916
Epoch 3/200, Training Loss: 31365.4916, Validation Loss: 23717.5938
Epoch 3: Validation loss improved to 23717.5938
Epoch 4/200, Training Loss: 19460.1830
Epoch 4/200, Training Loss: 19460.1830, Validation Loss: 16352.2793
Epoch 4: Validation loss improved to 16352.2793
Epoch 5/200, Training Loss: 13928.9534
Epoch 5/200, Training Loss: 13928.9534, Validation Loss: 11709.6475
Epoch 5: Validation loss improved to 11709.6475
Epoch 6/200, Training Loss: 11382.3403
Epoch 6/200, Training Loss: 11382.3403, Validation Loss: 10629.9463
Epoch 6: Validation loss improved to 10629.9463
Epoch 7/200, Training Loss: 10310.7606
Epoch 7/200, Training Loss: 10310.7606, Validation Loss: 9066.8564
Epoch 7: Validation loss improved to 9066.8564
Epoch 8/200, Training Loss: 9620.8685
Epoch 8/200, Training Loss: 9620.8685, Validation Loss: 7922.6689
Epoch 8: Validation loss improved to 7922.6689
Epoch 9/200, Training Loss: 7856.1243
Epoch 9/200, Training Loss: 7856.1243, Validation Loss: 8458.6982
Epoch 9: No improvement. EarlyStopping counter: 1/5
Epoch 10/200, Training Loss: 6708.8650
Epoch 10/200, Training Loss: 6708.8650, Validation Loss: 5658.9399
Epoch 10: Validation loss improved to 5658.9399
Epoch 11/200, Training Loss: 6827.8626
Epoch 11/200, Training Loss: 6827.8626, Validation Loss: 4872.7988
Epoch 11: Validation loss improved to 4872.7988
Epoch 12/200, Training Loss: 4857.9221
Epoch 12/200, Training Loss: 4857.9221, Validation Loss: 4434.4912
Epoch 12: Validation loss improved to 4434.4912
Epoch 13/200, Training Loss: 3864.9314
Epoch 13/200, Training Loss: 3864.9314, Validation Loss: 3276.3850
Epoch 13: Validation loss improved to 3276.3850
Epoch 14/200, Training Loss: 3145.4346
Epoch 14/200, Training Loss: 3145.4346, Validation Loss: 2548.2910
Epoch 14: Validation loss improved to 2548.2910
Epoch 15/200, Training Loss: 2297.2182
Epoch 15/200, Training Loss: 2297.2182, Validation Loss: 1762.7180
Epoch 15: Validation loss improved to 1762.7180
Epoch 16/200, Training Loss: 1576.1426
Epoch 16/200, Training Loss: 1576.1426, Validation Loss: 1207.4840
Epoch 16: Validation loss improved to 1207.4840
Epoch 17/200, Training Loss: 1144.0846
Epoch 17/200, Training Loss: 1144.0846, Validation Loss: 898.2933
Epoch 17: Validation loss improved to 898.2933
Epoch 18/200, Training Loss: 716.4119
Epoch 18/200, Training Loss: 716.4119, Validation Loss: 484.4124
Epoch 18: Validation loss improved to 484.4124
Epoch 19/200, Training Loss: 265.9596
Epoch 19/200, Training Loss: 265.9596, Validation Loss: 36.3732
Epoch 19: Validation loss improved to 36.3732
Epoch 20/200, Training Loss: 32.0119
Epoch 20/200, Training Loss: 32.0119, Validation Loss: 21.0155
Epoch 20: Validation loss improved to 21.0155
Epoch 21/200, Training Loss: 20.9333
Epoch 21/200, Training Loss: 20.9333, Validation Loss: 20.9390
Epoch 21: Validation loss improved to 20.9390
Epoch 22/200, Training Loss: 20.8728
Epoch 22/200, Training Loss: 20.8728, Validation Loss: 21.2219
Epoch 22: No improvement. EarlyStopping counter: 1/5
Epoch 23/200, Training Loss: 20.9571
Epoch 23/200, Training Loss: 20.9571, Validation Loss: 20.9648
Epoch 23: No improvement. EarlyStopping counter: 2/5
Epoch 24/200, Training Loss: 20.9739
Epoch 24/200, Training Loss: 20.9739, Validation Loss: 20.9764
Epoch 24: No improvement. EarlyStopping counter: 3/5
Epoch 25/200, Training Loss: 21.0266
Epoch 25/200, Training Loss: 21.0266, Validation Loss: 21.0949
Epoch 25: No improvement. EarlyStopping counter: 4/5
Epoch 26/200, Training Loss: 20.9834
Epoch 26/200, Training Loss: 20.9834, Validation Loss: 21.2489
Epoch 26: No improvement. EarlyStopping counter: 5/5
Early stopping triggered at epoch 26
Fold 5 completed.
[run1: 19.6619 run2: 21.0774 run3: 22.6657 run4: 19.6222 run5: 20.9390] avg loss: 20.7932 best loss: 19.6222 worst loss: 22.6657
